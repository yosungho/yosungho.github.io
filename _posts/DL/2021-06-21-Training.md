---
title: 'Neural Networks 잘 훈련시키는 방법'
categories:
  - DL
# tags:
#     - SLAM
description: >
  how to train Neural nets well
sitemap :
  changefreq : weekly
  priority : 1.0
published: true
---
_**신경망 학습을 할 때는 철저하고, 방어적이며, 편집증적이고, 가능한 모든 것을 시각화하는데 집착해야 합니다. 딥러닝의 성공과 연결되는 가장 중요한 자질은 바로 인내와 디테일에 대한 관심입니다. -Andrej Karpathy**_

이 글은 Andrej Karpathy가 소개한 'A Recipe for Training Neural Networks' 글을 정리한 자료입니다.

_**A Recipe for Training Neural Networks**_
=====================================
_**1. 데이터와 하나가 되어라 (Become one with the data)**_
----------------------------------------------------------
- 데이터에 대한 감잡기. 수천개의 데이터를 관찰하고, 분포를 파악해보고, 패턴을 찾아본다. 이를 통해 architecture에 대한 힌트를 얻을 수 있다. (local feature로 충분할지, global context가 필요한지, spatial position이 중요할지, average pooling이 나을지, 등..)
- 데이터를 필터링, 정렬하고 이를 시각화 한다. outlier를 찾아봄으로서 데이터의 품질을 검증한다.

_**2. 훈련/평가를 위한 end-to-end 골격을 잡아라. (Set up the end-to-end training/evaluation skeleton + get dumb baselines)**_
----------------------------------------------------------
- 골격 잡기. '간단한 모델'로 학습 시키고, loss를 시각화하고, 평가 메트릭 (e.g. accuracy), 모델 inference, 몇가지 가정에의한 ablation study를 수행해본다.
- 이 단계의 몇가지 Tips & Tricks:
  - fix random seed. (항상 같은 결과가 나오도록, 랜덤 시드를 고정하자.)
  - simplify. (예를들어 Data augmentation은 끄고, 나머지 부분에 실수가 없는지 확인하자.)
  - add significant digits to your eval. (test loss 등의 중요한 숫자를 전체 테스트셋에 대해 그려본다.)
  - verify loss @ init. (초기 loss값이 맞는 값으로 시작하는지 확인하자.)
  - init well. (마지막 레이어의 weight를 잘 초기화한다. 만약 평균이 50으로 예상된다면, 초기 예측값(bias)도 50이되도록 맞춘다. 이러면 더 빨리 수렴할거야.)
  - human baseline. (loss이외의 accuracy와 같이 사람이 해석하고 확인할 수 있는 metric도 GT값(baseline값)과 함께 모니터링 하자.)
  - input-indepent baseline. (입력을 0으로 주었을 때, 진짜 학습을 못하고 있는지 확인해보자.)
  - overfit one batch. (적은 수의 예제만을 갖고 overfit시켰을 때, 도달 가능한 가장 작은 loss가 얼마인지 확인해보고, 그 때 prediction이 GT와 완벽히 일치하는지 확인해보자. 이게 안되면 뭔가 버그가 있는거다.)
  - verify decreasing training loss. (모델 용량을 조금 크게 한 다음, loss가 여전히 줄어드는지 확인해보자.)
  - visualize just before the net. (모델에 넣기 '바로 전'에 입력 데이터를 시각화해보자. 데이터 전처리나 augmentation에서의 문제를 찾을 수 있는 가장 적합한 위치이다.)
  - visualize prediction dynamics. (학습 중에 특정 test배치에 대한 모델 예측값을 시각화하자. 학습 진행 상황에 대한 직관적 이해에 도움된다. 학습이 불안정한지, learning rate가 적당한지 등.)
  - use backprop to chart dependencies. (transpose/permute를 사용해야할 자리에 view를 사용하여 batch dimension이 섞이는 경우에 대한 debuging방법으로서 backprop을 사용한다. i번째 예제에 대해서면 loss값을 단순한 값(출력의 합)으로 줘서 이 때만 non-zero gradient가 발생하는지 확인해보고 이런 식으로 디버깅할 수 있다.)
  - generalize a special case. (아주 특정한 목적을 가지고 있는 함수 구현/검증을 먼저하고, 이를 일반화하는 함수로 확장한다.)

_**3. 과적합 시키기 (Overfit)**_
----------------------------------------------------------
이전까지의 과정을 통해, dataset이해 + 전체 training + evaluation 파이프라인이 완성되었을 것이다. 이제 좋은 모델 찾기 과정은 다음 두가지로 이루어진다. (1) training loss를 확인하며 충분히 overfit할 수 있는 모델을 가져온다. (2) 이후 일반화를 적절히 하여 validation loss를 줄인다.
- 이 단계의 몇가지 Tips & Tricks:
  - picking the model.
  - adam is safe.
  - complexify only one at a time.
  - do not trust learning rate decay defaults.

_**4. 일반화 시키기 (Regularize)**_
----------------------------------------------------------
- 이 단계의 몇가지 Tips & Tricks:
  - get more data.
  - data augment.
  - creative augmentation.
  - pretrain.
  - stick with supervised learning.
  - smaller input dimensionality.
  - smaller model size.
  - decrease the batch size.
  - drop.
  - weight decay.
  - early stopping.
  - try a larger model.

_**5. 튜닝 (Tune)**_
----------------------------------------------------------
- 이 단계의 몇가지 Tips & Tricks:
  - random over grid search.
  - hyper-parameter optimization.

_**6. 성능 짜내기 (Squeeze out the juice)**_
----------------------------------------------------------
- 이 단계의 몇가지 Tips & Tricks:
  - ensembles.
  - leave it training.


_**이외의 사람들이 하는 실수들...**_
----------------------------------------------------------
- train / eval 모드를 toggle하지 않았다.
- backward() 전에 zero_grad()를 하지 않았다.
- loss값에 softmax의 출력을 그대로 넣었다.
- BatchNorm을 사용할 때 Linear/Conv2d에 bias=False를 하지 않았다.
- output layer에서 bias=True를 하지 않았다.
- view()와 .permute()를 같은 것으로 생각한다.
